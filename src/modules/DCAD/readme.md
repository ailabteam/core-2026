# DCAD - Document Collection And Digitization

**Pipeline chu·∫©n x·ª≠ l√Ω ·∫£nh t√†i li·ªáu (Document Image Enhancement)**

Module DCAD cung c·∫•p m·ªôt pipeline ho√†n ch·ªânh ƒë·ªÉ x·ª≠ l√Ω v√† tƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng ·∫£nh t√†i li·ªáu, chu·∫©n b·ªã cho c√°c b∆∞·ªõc OCR v√† ph√¢n t√≠ch AI ti·∫øp theo.

---

## üìã T·ªïng quan

DCAD x·ª≠ l√Ω ·∫£nh t√†i li·ªáu qua 5 b∆∞·ªõc ch√≠nh:

```
Input (camera/scan/PDF)
   ‚Üì
[1] Chu·∫©n ho√° ƒë·∫ßu v√†o (format, DPI, m√†u)
   ‚Üì
[2] CƒÉn ch·ªânh & s·ª≠a m√©o (deskew / dewarp)
   ‚Üì
[3] Crop v√πng t√†i li·ªáu
   ‚Üì
[4] Kh·ª≠ nhi·ªÖu & tƒÉng ch·∫•t l∆∞·ª£ng
   ‚Üì
[5] Chu·∫©n ho√° cho OCR / AI
   ‚Üì
Output (·∫£nh s·∫°ch + metadata)
```

---

## üöÄ C√†i ƒë·∫∑t

### Y√™u c·∫ßu

- Python 3.8+
- pip ho·∫∑c conda

### C√†i ƒë·∫∑t dependencies

```bash
cd src/modules/DCAD

pip install -r requirements.txt
```

### Dependencies ch√≠nh

- **opencv-python** - X·ª≠ l√Ω ·∫£nh core
- **Pillow** - I/O ·∫£nh
- **pdf2image** - Chuy·ªÉn ƒë·ªïi PDF
- **numpy** - T√≠nh to√°n s·ªë h·ªçc
- **scikit-image** - X·ª≠ l√Ω ·∫£nh n√¢ng cao
- **scipy** - T√≠nh to√°n khoa h·ªçc

---

## üí° S·ª≠ d·ª•ng c∆° b·∫£n

### Quick Start

```python
from modules.DCAD.app import DocumentEnhancer

# Kh·ªüi t·∫°o
enhancer = DocumentEnhancer()

# X·ª≠ l√Ω ·∫£nh
enhanced_image, metadata = enhancer.process('path/to/document.jpg')

# Ho·∫∑c d√πng quick enhance
from modules.DCAD.app import quick_enhance
enhanced_image, metadata = quick_enhance('path/to/document.jpg')
```

### X·ª≠ l√Ω PDF

```python
# X·ª≠ l√Ω trang PDF
enhancer = DocumentEnhancer()
enhanced, metadata = enhancer.process('document.pdf', input_type='pdf')
```

### X·ª≠ l√Ω batch

```python
# X·ª≠ l√Ω nhi·ªÅu ·∫£nh
image_paths = ['img1.jpg', 'img2.jpg', 'img3.jpg']
results = enhancer.process_batch(image_paths)

for enhanced_image, metadata in results:
    print(f"Processing time: {metadata['processing_time_ms']} ms")
```

### Configuration t√πy ch·ªânh

```python
enhancer = DocumentEnhancer(
    target_dpi=300,          # DPI m·ª•c ti√™u
    grayscale=True,          # Chuy·ªÉn sang grayscale
    enable_deskew=True,      # B·∫≠t t·ª± ƒë·ªông xoay
    enable_crop=True,        # B·∫≠t t·ª± ƒë·ªông crop
    enable_enhance=True,     # B·∫≠t tƒÉng c∆∞·ªùng
    enable_ocr_prep=True     # B·∫≠t chu·∫©n b·ªã OCR
)

enhanced, metadata = enhancer.process('image.jpg')
```

---

## üìñ API Reference

### Class: `DocumentEnhancer`

Pipeline ch√≠nh ƒë·ªÉ x·ª≠ l√Ω ·∫£nh t√†i li·ªáu.

#### Constructor

```python
DocumentEnhancer(
    target_dpi: int = 300,
    grayscale: bool = True,
    enable_deskew: bool = True,
    enable_crop: bool = True,
    enable_enhance: bool = True,
    enable_ocr_prep: bool = True
)
```

**Parameters:**
- `target_dpi` - DPI m·ª•c ti√™u cho output (m·∫∑c ƒë·ªãnh: 300)
- `grayscale` - Chuy·ªÉn sang grayscale (m·∫∑c ƒë·ªãnh: True)
- `enable_deskew` - B·∫≠t t·ª± ƒë·ªông cƒÉn ch·ªânh g√≥c (m·∫∑c ƒë·ªãnh: True)
- `enable_crop` - B·∫≠t t·ª± ƒë·ªông crop t√†i li·ªáu (m·∫∑c ƒë·ªãnh: True)
- `enable_enhance` - B·∫≠t kh·ª≠ nhi·ªÖu v√† tƒÉng c∆∞·ªùng (m·∫∑c ƒë·ªãnh: True)
- `enable_ocr_prep` - B·∫≠t chu·∫©n b·ªã cho OCR (m·∫∑c ƒë·ªãnh: True)

#### Methods

##### `process(input_source, input_type='auto')`

X·ª≠ l√Ω m·ªôt ·∫£nh/PDF th√¥ng qua to√†n b·ªô pipeline.

**Parameters:**
- `input_source` (str | np.ndarray) - ƒê∆∞·ªùng d·∫´n ho·∫∑c numpy array
- `input_type` (str) - Lo·∫°i input: 'image', 'pdf', ho·∫∑c 'auto'

**Returns:**
- `tuple[np.ndarray, dict]` - (enhanced_image, metadata)

**Example:**
```python
enhanced, metadata = enhancer.process('document.jpg')
```

##### `process_batch(input_sources, input_type='auto')`

X·ª≠ l√Ω nhi·ªÅu ·∫£nh c√πng l√∫c.

**Parameters:**
- `input_sources` (list) - Danh s√°ch ƒë∆∞·ªùng d·∫´n ho·∫∑c arrays
- `input_type` (str) - Lo·∫°i input

**Returns:**
- `list[tuple]` - Danh s√°ch (enhanced_image, metadata)

##### `normalize_input(image)`

**Stage 1:** Chu·∫©n h√≥a format, DPI, v√† m√†u s·∫Øc.

##### `align_image(image)`

**Stage 2:** CƒÉn ch·ªânh v√† xoay ·∫£nh s·ª≠ d·ª•ng Hough Transform.

**Returns:** `(aligned_image, rotation_angle)`

##### `crop_document(image)`

**Stage 3:** Ph√°t hi·ªán v√† crop bi√™n t√†i li·ªáu.

**Returns:** `(cropped_image, corner_coordinates)` ho·∫∑c `None`

##### `denoise_enhance(image)`

**Stage 4:** Kh·ª≠ nhi·ªÖu v√† tƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng.

**Returns:** `(enhanced_image, enhancement_params)`

##### `prepare_for_ocr(image)`

**Stage 5:** Chu·∫©n b·ªã cho OCR v·ªõi adaptive threshold.

**Returns:** `ocr_ready_image`

##### `get_config()`

L·∫•y c·∫•u h√¨nh hi·ªán t·∫°i.

**Returns:** `dict` - Configuration dictionary

---

### Function: `quick_enhance()`

H√†m ti·ªán √≠ch cho x·ª≠ l√Ω nhanh v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh.

```python
quick_enhance(input_source, grayscale=True)
```

**Example:**
```python
from modules.DCAD.app import quick_enhance
enhanced, metadata = quick_enhance('document.jpg')
```

---

## üìä Metadata Structure

M·ªói l·∫ßn x·ª≠ l√Ω s·∫Ω tr·∫£ v·ªÅ metadata chi ti·∫øt:

```python
metadata = {
    'input_type': 'image',              # Lo·∫°i input
    'original_size': (1920, 1080),      # K√≠ch th∆∞·ªõc g·ªëc (w, h)
    'processing_steps': [               # C√°c b∆∞·ªõc ƒë√£ th·ª±c hi·ªán
        'normalize', 
        'deskew', 
        'crop', 
        'enhance', 
        'ocr_prep'
    ],
    'rotation_angle': -2.3,             # G√≥c xoay (ƒë·ªô)
    'crop_coordinates': [               # T·ªça ƒë·ªô crop (n·∫øu c√≥)
        [10, 20], 
        [1910, 25], 
        [1905, 1075], 
        [15, 1070]
    ],
    'enhancement_params': {             # Tham s·ªë tƒÉng c∆∞·ªùng
        'bilateral_d': 9,
        'median_kernel': 3,
        'clahe_clip': 2.0,
        'clahe_grid': (8, 8),
        'unsharp_amount': 0.5
    },
    'quality_metrics': {                # Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng
        'sharpness': 1234.56,
        'contrast': 78.9,
        'brightness': 145.2,
        'overall_score': 2.02
    },
    'final_size': (1754, 2480),         # K√≠ch th∆∞·ªõc cu·ªëi (w, h)
    'processing_time_ms': 1234.56       # Th·ªùi gian x·ª≠ l√Ω (ms)
}
```

---

## üîß Configuration

### File: `config.py`

T·∫•t c·∫£ tham s·ªë c√≥ th·ªÉ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh trong `config.py`:

```python
# Target dimensions
TARGET_DPI = 300
TARGET_HEIGHT = 2480
TARGET_WIDTH = 1754

# Filters
MEDIAN_KERNEL_SIZE = 3
BILATERAL_D = 9

# CLAHE
CLAHE_CLIP_LIMIT = 2.0
CLAHE_TILE_GRID_SIZE = (8, 8)

# Edge detection
CANNY_THRESHOLD1 = 50
CANNY_THRESHOLD2 = 150

# Adaptive threshold
ADAPTIVE_BLOCK_SIZE = 11
ADAPTIVE_C = 2

# Hough Transform
HOUGH_THRESHOLD = 100
HOUGH_MIN_LINE_LENGTH = 100
HOUGH_MAX_LINE_GAP = 10
```

### Tuning Tips

**N·∫øu ·∫£nh qu√° t·ªëi:**
- TƒÉng `CLAHE_CLIP_LIMIT` (2.0 ‚Üí 3.0)
- Gi·∫£m `ADAPTIVE_C` (2 ‚Üí 1)

**N·∫øu nhi·ªÖu nhi·ªÅu:**
- TƒÉng `MEDIAN_KERNEL_SIZE` (3 ‚Üí 5)
- TƒÉng `BILATERAL_D` (9 ‚Üí 11)

**N·∫øu kh√¥ng detect ƒë∆∞·ª£c g√≥c xoay:**
- Gi·∫£m `HOUGH_THRESHOLD` (100 ‚Üí 50)
- TƒÉng `HOUGH_MIN_LINE_LENGTH` (100 ‚Üí 150)

**N·∫øu crop kh√¥ng ch√≠nh x√°c:**
- ƒêi·ªÅu ch·ªânh `CANNY_THRESHOLD1` v√† `CANNY_THRESHOLD2`
- TƒÉng `CONTOUR_EPSILON_FACTOR` (0.02 ‚Üí 0.03)

---

## üéØ Chi ti·∫øt k·ªπ thu·∫≠t

### Stage 1: Normalize Input

**M·ª•c ƒë√≠ch:** ƒê∆∞a m·ªçi input v·ªÅ c√πng chu·∫©n

**K·ªπ thu·∫≠t:**
- Convert PDF ‚Üí Image (300 DPI)
- Chuy·ªÉn v·ªÅ grayscale
- Resize theo chi·ªÅu d√†i chu·∫©n (2480px ~ A4 @300dpi)
- Maintain aspect ratio

### Stage 2: Deskew

**M·ª•c ƒë√≠ch:** CƒÉn ch·ªânh ·∫£nh b·ªã nghi√™ng

**K·ªπ thu·∫≠t:** Hough Line Transform
```python
# Detect edges
edges = cv2.Canny(gray, 50, 150)

# Detect lines
lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, 
                        threshold=100, minLineLength=100)

# Calculate median angle
angles = [arctan2(y2-y1, x2-x1) for each line]
rotation_angle = median(angles)

# Rotate image
M = cv2.getRotationMatrix2D(center, angle, 1.0)
rotated = cv2.warpAffine(image, M, (w, h))
```

**∆Øu ƒëi·ªÉm:**
- Robust v·ªõi nhi·ªÖu
- C√≥ th·ªÉ detect multiple lines
- S·ª≠ d·ª•ng median ƒë·ªÉ tr√°nh outliers

### Stage 3: Crop Document

**M·ª•c ƒë√≠ch:** Lo·∫°i b·ªè n·ªÅn, tay ng∆∞·ªùi, b√≥ng

**K·ªπ thu·∫≠t:** Contour detection + Perspective transform
```python
# Edge detection
edges = cv2.Canny(blurred, 50, 150)

# Find contours
contours = cv2.findContours(edges, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE)

# Get largest quadrilateral
largest = max(contours, key=cv2.contourArea)
approx = cv2.approxPolyDP(largest, epsilon, True)

# Perspective transform
M = cv2.getPerspectiveTransform(src_points, dst_points)
warped = cv2.warpPerspective(image, M, (w, h))
```

### Stage 4: Denoise & Enhance

**M·ª•c ƒë√≠ch:** TƒÉng ch·∫•t l∆∞·ª£ng cho OCR

**Pipeline:**
1. **Bilateral Filter** - Kh·ª≠ nhi·ªÖu gi·ªØ edge
2. **Median Filter** - Lo·∫°i salt-and-pepper noise
3. **CLAHE** - TƒÉng contrast c·ª•c b·ªô
4. **Unsharp Masking** - L√†m s·∫Øc n√©t

```python
# Bilateral filter
enhanced = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)

# Median filter
enhanced = cv2.medianBlur(enhanced, 3)

# CLAHE
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
enhanced = clahe.apply(enhanced)

# Unsharp mask
blurred = cv2.GaussianBlur(enhanced, (5,5), 1.0)
enhanced = cv2.addWeighted(enhanced, 1.5, blurred, -0.5, 0)
```

**CLAHE l√† g√¨?**
- Contrast Limited Adaptive Histogram Equalization
- TƒÉng contrast c·ª•c b·ªô m√† kh√¥ng l√†m qu√° s√°ng v√πng ƒë·ªìng nh·∫•t
- R·∫•t hi·ªáu qu·∫£ cho t√†i li·ªáu c√≥ √°nh s√°ng kh√¥ng ƒë·ªÅu

### Stage 5: OCR Preparation

**M·ª•c ƒë√≠ch:** Output l√Ω t∆∞·ªüng cho OCR

**Y√™u c·∫ßu output:**
- ‚úÖ 300 DPI
- ‚úÖ Background tr·∫Øng
- ‚úÖ Text ƒëen
- ‚úÖ Kh√¥ng b√≥ng, kh√¥ng nhi·ªÖu
- ‚úÖ Binary image

**K·ªπ thu·∫≠t:** Adaptive Threshold + Morphology
```python
# Adaptive threshold
binary = cv2.adaptiveThreshold(
    gray, 255, 
    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY, 11, 2
)

# Morphological operations
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))

# Remove noise
opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)

# Fill holes
closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
```

**T·∫°i sao d√πng Adaptive Threshold?**
- X·ª≠ l√Ω ƒë∆∞·ª£c ·∫£nh c√≥ √°nh s√°ng kh√¥ng ƒë·ªÅu
- T·ªët h∆°n global threshold
- T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh theo t·ª´ng v√πng

---

## üìù Examples

### Example 1: X·ª≠ l√Ω ·∫£nh ch·ª•p t·ª´ ƒëi·ªán tho·∫°i

```python
from modules.DCAD.app import DocumentEnhancer

# ·∫¢nh ch·ª•p t·ª´ camera th∆∞·ªùng b·ªã nghi√™ng, c√≥ b√≥ng
enhancer = DocumentEnhancer(
    grayscale=True,
    enable_deskew=True,   # S·ª≠a g√≥c nghi√™ng
    enable_crop=True,     # Lo·∫°i b·ªè n·ªÅn
    enable_enhance=True   # Kh·ª≠ b√≥ng v√† nhi·ªÖu
)

enhanced, metadata = enhancer.process('photo_from_phone.jpg')

print(f"ƒê√£ xoay: {metadata['rotation_angle']}¬∞")
print(f"Ch·∫•t l∆∞·ª£ng: {metadata['quality_metrics']['overall_score']}")
```

### Example 2: X·ª≠ l√Ω scan ch·∫•t l∆∞·ª£ng cao

```python
# Scan th∆∞·ªùng ƒë√£ th·∫≥ng v√† s·∫°ch, ch·ªâ c·∫ßn enhance
enhancer = DocumentEnhancer(
    grayscale=True,
    enable_deskew=False,  # Kh√¥ng c·∫ßn xoay
    enable_crop=False,    # Kh√¥ng c·∫ßn crop
    enable_enhance=True,  # Ch·ªâ tƒÉng c∆∞·ªùng
    enable_ocr_prep=True  # Chu·∫©n b·ªã OCR
)

enhanced, metadata = enhancer.process('scanned_doc.jpg')
```

### Example 3: X·ª≠ l√Ω PDF nhi·ªÅu trang

```python
from pdf2image import convert_from_path

# Convert all pages
images = convert_from_path('document.pdf', dpi=300)

enhancer = DocumentEnhancer()
enhanced_pages = []

for i, img in enumerate(images):
    # Convert PIL to numpy
    img_array = np.array(img)
    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    
    # Process
    enhanced, metadata = enhancer.process(img_bgr)
    enhanced_pages.append(enhanced)
    
    print(f"Page {i+1}: {metadata['processing_time_ms']} ms")
```

### Example 4: Batch processing v·ªõi output

```python
import os
from pathlib import Path

# Setup
input_dir = Path('input_images')
output_dir = Path('output_enhanced')
output_dir.mkdir(exist_ok=True)

# Get all images
image_files = list(input_dir.glob('*.jpg')) + list(input_dir.glob('*.png'))

# Process
enhancer = DocumentEnhancer()

for img_path in image_files:
    enhanced, metadata = enhancer.process(str(img_path))
    
    # Save
    output_path = output_dir / f"{img_path.stem}_enhanced.png"
    cv2.imwrite(str(output_path), enhanced)
    
    print(f"‚úÖ {img_path.name} ‚Üí {output_path.name}")
```

---

## üß™ Testing

### Ch·∫°y examples

```bash
cd src/modules/DCAD
python example_usage.py
```

Menu s·∫Ω hi·ªán ra v·ªõi c√°c t√πy ch·ªçn:
1. Basic Usage
2. PDF Processing
3. Custom Configuration
4. Stage-by-Stage Processing
5. Batch Processing
6. Quick Enhance

### Test v·ªõi CLI

```bash
python app.py path/to/image.jpg
```

### Test t·ª´ng stage

```python
from modules.DCAD.app import DocumentEnhancer
import cv2

enhancer = DocumentEnhancer()
img = cv2.imread('test.jpg')

# Test t·ª´ng stage
stage1 = enhancer.normalize_input(img)
stage2, angle = enhancer.align_image(stage1)
stage3_result = enhancer.crop_document(stage2)
if stage3_result:
    stage3, coords = stage3_result
else:
    stage3 = stage2
stage4, params = enhancer.denoise_enhance(stage3)
stage5 = enhancer.prepare_for_ocr(stage4)

# Visualize
import matplotlib.pyplot as plt
stages = [img, stage1, stage2, stage3, stage4, stage5]
titles = ['Original', 'Normalized', 'Aligned', 'Cropped', 'Enhanced', 'OCR Ready']

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
for ax, stage, title in zip(axes.flat, stages, titles):
    ax.imshow(stage if len(stage.shape) == 3 else stage, cmap='gray')
    ax.set_title(title)
    ax.axis('off')
plt.show()
```

---

## üîó Integration

### T√≠ch h·ª£p v·ªõi OCR pipeline

```python
from modules.DCAD.app import DocumentEnhancer
from modules.daft.ocr.gemini_client import GeminiOCR

# Step 1: Enhance image
enhancer = DocumentEnhancer()
enhanced, metadata = enhancer.process('document.jpg')

# Step 2: OCR
ocr = GeminiOCR()
text = ocr.extract_text(enhanced)

print(f"Processing time: {metadata['processing_time_ms']} ms")
print(f"Extracted text: {text}")
```

### T√≠ch h·ª£p v·ªõi Signature Detection

```python
from modules.DCAD.app import DocumentEnhancer
from modules.SAS.detector import SignatureDetector

# Step 1: Enhance
enhancer = DocumentEnhancer()
enhanced, metadata = enhancer.process('contract.jpg')

# Step 2: Detect signatures
detector = SignatureDetector()
signatures = detector.detect(enhanced)

print(f"Found {len(signatures)} signatures")
```

### T√≠ch h·ª£p v√†o Web API

```python
from fastapi import FastAPI, UploadFile
from modules.DCAD.app import DocumentEnhancer
import cv2
import numpy as np

app = FastAPI()
enhancer = DocumentEnhancer()

@app.post("/enhance")
async def enhance_document(file: UploadFile):
    # Read file
    contents = await file.read()
    nparr = np.frombuffer(contents, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    # Process
    enhanced, metadata = enhancer.process(img)
    
    # Encode to bytes
    _, buffer = cv2.imencode('.png', enhanced)
    
    return {
        "image": buffer.tobytes(),
        "metadata": metadata
    }
```

---

## ‚ö° Performance

### Benchmarks

Th·ªùi gian x·ª≠ l√Ω trung b√¨nh (Intel Core i7, 16GB RAM):

| Image Size | Processing Time | Notes |
|------------|----------------|-------|
| 1920x1080 | ~500 ms | Camera photo |
| 2480x3508 (A4@300dpi) | ~800 ms | Scan |
| 3840x2160 (4K) | ~1200 ms | High-res |

### Optimization Tips

**ƒê·ªÉ tƒÉng t·ªëc:**
1. **Disable c√°c stage kh√¥ng c·∫ßn:**
   ```python
   enhancer = DocumentEnhancer(
       enable_crop=False,    # N·∫øu ·∫£nh ƒë√£ crop s·∫µn
       enable_deskew=False   # N·∫øu ·∫£nh ƒë√£ th·∫≥ng
   )
   ```

2. **Gi·∫£m resolution tr∆∞·ªõc khi x·ª≠ l√Ω:**
   ```python
   # Resize xu·ªëng tr∆∞·ªõc
   small = cv2.resize(img, None, fx=0.5, fy=0.5)
   enhanced, _ = enhancer.process(small)
   ```

3. **Batch processing thay v√¨ t·ª´ng ·∫£nh:**
   ```python
   # Nhanh h∆°n v√¨ reuse enhancer instance
   results = enhancer.process_batch(image_paths)
   ```

---

## üêõ Troubleshooting

### V·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p

**1. ImportError: No module named 'cv2'**
```bash
pip install opencv-python
```

**2. pdf2image: PDFPageCountError**
```bash
# MacOS
brew install poppler

# Ubuntu
sudo apt-get install poppler-utils

# Windows: Download poppler binary
```

**3. ·∫¢nh b·ªã xoay ng∆∞·ª£c**

ƒêi·ªÅu ch·ªânh `MAX_SKEW_ANGLE` trong `config.py`:
```python
MAX_SKEW_ANGLE = 10  # Gi·∫£m xu·ªëng n·∫øu xoay qu√° nhi·ªÅu
```

**4. Crop kh√¥ng ch√≠nh x√°c**

ƒêi·ªÅu ch·ªânh edge detection:
```python
CANNY_THRESHOLD1 = 30  # Th·ª≠ gi·∫£m xu·ªëng
CANNY_THRESHOLD2 = 100
```

**5. ·∫¢nh qu√° t·ªëi sau enhance**

TƒÉng CLAHE:
```python
CLAHE_CLIP_LIMIT = 3.0  # TƒÉng l√™n
```

**6. Nhi·ªÖu nhi·ªÅu sau OCR prep**

TƒÉng median filter:
```python
MEDIAN_KERNEL_SIZE = 5  # TƒÉng l√™n (ph·∫£i l√† s·ªë l·∫ª)
```

---

## üìÑ License

MIT License - T·ª± do s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch c√° nh√¢n v√† th∆∞∆°ng m·∫°i.

---

## üôã Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ ho·∫∑c c√≥ c√¢u h·ªèi:

1. Ki·ªÉm tra [Troubleshooting](#-troubleshooting)
2. Xem [Examples](#-examples)
3. Review [API Reference](#-api-reference)

---

## üîÆ Roadmap

T√≠nh nƒÉng s·∫Øp t·ªõi:

- [ ] Dewarp (s·ª≠a m√©o cho s√°ch)
- [ ] Shadow removal (lo·∫°i b√≥ng th√¥ng minh)
- [ ] Text line detection
- [ ] Multi-language support trong docs
- [ ] GPU acceleration v·ªõi CUDA
- [ ] Pre-trained models cho crop & deskew
- [ ] Web interface demo

---

**Made with ‚ù§Ô∏è for CORE AI HUB**

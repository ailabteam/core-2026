{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14166537,"sourceType":"datasetVersion","datasetId":9029991}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U pip setuptools wheel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:29:36.536278Z","iopub.execute_input":"2025-12-15T17:29:36.536778Z","iopub.status.idle":"2025-12-15T17:29:54.255173Z","shell.execute_reply.started":"2025-12-15T17:29:36.536751Z","shell.execute_reply":"2025-12-15T17:29:54.254425Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\nCollecting setuptools\n  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools, pip\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 75.2.0\n    Uninstalling setuptools-75.2.0:\n      Successfully uninstalled setuptools-75.2.0\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 \\\n  --index-url https://download.pytorch.org/whl/cu118","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:29:54.256809Z","iopub.execute_input":"2025-12-15T17:29:54.257058Z","iopub.status.idle":"2025-12-15T17:31:56.098914Z","shell.execute_reply.started":"2025-12-15T17:29:54.257032Z","shell.execute_reply":"2025-12-15T17:31:56.097964Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nCollecting torch==2.0.1+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m  \u001b[33m0:00:52\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.0.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.20.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\nCollecting triton==2.0.0 (from torch==2.0.1+cu118)\n  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.32.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.3.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\nCollecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.15.2+cu118) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.10.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\nBuilding wheels for collected packages: lit\n  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89991 sha256=5825381c811816641b3535fbd6de2bdcfa97331a428de7dfebe2c060ae8a4722\n  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\nSuccessfully built lit\nInstalling collected packages: lit, triton, torch, torchvision, torchaudio\n\u001b[2K  Attempting uninstall: triton\n\u001b[2K    Found existing installation: triton 3.2.0\n\u001b[2K    Uninstalling triton-3.2.0:\n\u001b[2K      Successfully uninstalled triton-3.2.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [triton]\n\u001b[2K  Attempting uninstall: torchm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [triton]\n\u001b[2K    Found existing installation: torch 2.6.0+cu124━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K    Uninstalling torch-2.6.0+cu124:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K      Successfully uninstalled torch-2.6.0+cu124━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K  Attempting uninstall: torchvision[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K    Found existing installation: torchvision 0.21.0+cu124━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K    Uninstalling torchvision-0.21.0+cu124:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K      Successfully uninstalled torchvision-0.21.0+cu124━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K  Attempting uninstall: torchaudio0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K    Found existing installation: torchaudio 2.6.0+cu124[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [torchaudio]\n\u001b[2K    Uninstalling torchaudio-2.6.0+cu124:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [torchaudio]\n\u001b[2K      Successfully uninstalled torchaudio-2.6.0+cu1240m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [torchaudio]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [torchaudio]5\u001b[0m [torchaudio]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.5.5 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install xformers==0.0.21","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:31:56.100056Z","iopub.execute_input":"2025-12-15T17:31:56.100495Z","iopub.status.idle":"2025-12-15T17:32:03.486803Z","shell.execute_reply.started":"2025-12-15T17:31:56.100459Z","shell.execute_reply":"2025-12-15T17:32:03.486089Z"}},"outputs":[{"name":"stdout","text":"Collecting xformers==0.0.21\n  Downloading xformers-0.0.21-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.21) (1.26.4)\nRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.21) (2.0.1+cu118)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (3.20.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (3.1.6)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.21) (2.0.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.21) (3.31.6)\nRequirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.21) (15.0.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->xformers==0.0.21) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.21) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers==0.0.21) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers==0.0.21) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers==0.0.21) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xformers==0.0.21) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xformers==0.0.21) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xformers==0.0.21) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->xformers==0.0.21) (1.3.0)\nDownloading xformers-0.0.21-cp311-cp311-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xformers\nSuccessfully installed xformers-0.0.21\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:03.488585Z","iopub.execute_input":"2025-12-15T17:32:03.488812Z","iopub.status.idle":"2025-12-15T17:32:33.667943Z","shell.execute_reply.started":"2025-12-15T17:32:03.488788Z","shell.execute_reply":"2025-12-15T17:32:33.667140Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-qz2ao4ys\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-qz2ao4ys\n  Resolved https://github.com/huggingface/transformers to commit 06378d40e613db0dfbfb79a5569017bae83d3929\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\nCollecting huggingface-hub<2.0,>=1.2.1 (from transformers==5.0.0.dev0)\n  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers==5.0.0.dev0)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.28.1)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.5.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.15.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==5.0.0.dev0) (2.4.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==5.0.0.dev0) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==5.0.0.dev0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==5.0.0.dev0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.0)\nDownloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\nDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10907042 sha256=01a41988fb61fa2ed012bdcd586c26dd4b882b3b5bacdf61bc393b94ded7550e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-2c_gplwx/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\nSuccessfully built transformers\nInstalling collected packages: huggingface-hub, tokenizers, transformers\n\u001b[2K  Attempting uninstall: huggingface-hub\n\u001b[2K    Found existing installation: huggingface-hub 0.36.0\n\u001b[2K    Uninstalling huggingface-hub-0.36.0:\n\u001b[2K      Successfully uninstalled huggingface-hub-0.36.0\n\u001b[2K  Attempting uninstall: tokenizers━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [huggingface-hub]\n\u001b[2K    Found existing installation: tokenizers 0.21.2[32m0/3\u001b[0m [huggingface-hub]\n\u001b[2K    Uninstalling tokenizers-0.21.2:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tokenizers]\n\u001b[2K      Successfully uninstalled tokenizers-0.21.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tokenizers]\n\u001b[2K  Attempting uninstall: transformers━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tokenizers]\n\u001b[2K    Found existing installation: transformers 4.53.3━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [tokenizers]\n\u001b[2K    Uninstalling transformers-4.53.3:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [transformers]\n\u001b[2K      Successfully uninstalled transformers-4.53.390m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [transformers]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [transformers][0m [transformers]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-1.2.3 tokenizers-0.22.1 transformers-5.0.0.dev0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%bash\ngit clone https://github.com/deepseek-ai/DeepSeek-VL2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:33.668863Z","iopub.execute_input":"2025-12-15T17:32:33.669155Z","iopub.status.idle":"2025-12-15T17:32:36.180022Z","shell.execute_reply.started":"2025-12-15T17:32:33.669107Z","shell.execute_reply":"2025-12-15T17:32:36.179444Z"}},"outputs":[{"name":"stderr","text":"Cloning into 'DeepSeek-VL2'...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%cd DeepSeek-VL2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:36.180711Z","iopub.execute_input":"2025-12-15T17:32:36.180980Z","iopub.status.idle":"2025-12-15T17:32:36.186185Z","shell.execute_reply.started":"2025-12-15T17:32:36.180956Z","shell.execute_reply":"2025-12-15T17:32:36.185484Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/DeepSeek-VL2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:36.186949Z","iopub.execute_input":"2025-12-15T17:32:36.187228Z","iopub.status.idle":"2025-12-15T17:32:50.809711Z","shell.execute_reply.started":"2025-12-15T17:32:36.187204Z","shell.execute_reply":"2025-12-15T17:32:50.808801Z"}},"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/DeepSeek-VL2\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (2.0.1+cu118)\nCollecting transformers==4.38.2 (from deepseek_vl2==1.0.0)\n  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\nRequirement already satisfied: timm>=0.9.16 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.0.19)\nRequirement already satisfied: xformers>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.0.21)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.9.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.2.0)\nCollecting attrdict (from deepseek_vl2==1.0.0)\n  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.20.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.1.6)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (2.0.0)\nCollecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38.2->deepseek_vl2==1.0.0)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.32.5)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->deepseek_vl2==1.0.0)\n  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (4.67.1)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (3.31.6)\nRequirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (15.0.7)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2.4.1)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->deepseek_vl2==1.0.0) (0.15.2+cu118)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->deepseek_vl2==1.0.0) (7.1.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->deepseek_vl2==1.0.0) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->deepseek_vl2==1.0.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.38.2->deepseek_vl2==1.0.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.10.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->deepseek_vl2==1.0.0) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.16->deepseek_vl2==1.0.0) (11.3.0)\nDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: deepseek_vl2\n  Building editable for deepseek_vl2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for deepseek_vl2: filename=deepseek_vl2-1.0.0-0.editable-py3-none-any.whl size=14553 sha256=8a5d41c7e71a5875fdd6d292b7f4fcb29cac91b93534c96f92b32bc798b02228\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dg38katr/wheels/c7/0a/ec/dd262d2d48e0c2858d56d6aa53ad9be1fa6a602d732bced2ea\nSuccessfully built deepseek_vl2\nInstalling collected packages: attrdict, huggingface-hub, tokenizers, transformers, deepseek_vl2\n\u001b[2K  Attempting uninstall: huggingface-hub\n\u001b[2K    Found existing installation: huggingface_hub 1.2.3\n\u001b[2K    Uninstalling huggingface_hub-1.2.3:\n\u001b[2K      Successfully uninstalled huggingface_hub-1.2.3\n\u001b[2K  Attempting uninstall: tokenizersm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [huggingface-hub]\n\u001b[2K    Found existing installation: tokenizers 0.22.1━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [huggingface-hub]\n\u001b[2K    Uninstalling tokenizers-0.22.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [huggingface-hub]\n\u001b[2K      Successfully uninstalled tokenizers-0.22.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [huggingface-hub]\n\u001b[2K  Attempting uninstall: transformers0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [tokenizers]]\n\u001b[2K    Found existing installation: transformers 5.0.0.dev0━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [tokenizers]\n\u001b[2K    Uninstalling transformers-5.0.0.dev0:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [transformers]\n\u001b[2K      Successfully uninstalled transformers-5.0.0.dev0━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [transformers]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [deepseek_vl2][0m [transformers]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed attrdict-2.0.1 deepseek_vl2-1.0.0 huggingface-hub-0.36.0 tokenizers-0.15.2 transformers-4.38.2\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport xformers\nimport transformers\nprint(\"OK\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:50.810827Z","iopub.execute_input":"2025-12-15T17:32:50.811142Z","iopub.status.idle":"2025-12-15T17:32:54.965707Z","shell.execute_reply.started":"2025-12-15T17:32:50.811089Z","shell.execute_reply":"2025-12-15T17:32:54.964943Z"}},"outputs":[{"name":"stdout","text":"OK\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom deepseek_vl2.models import DeepseekVLV2ForCausalLM\nfrom deepseek_vl2.models import DeepseekVLV2Processor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:32:54.966559Z","iopub.execute_input":"2025-12-15T17:32:54.966938Z","iopub.status.idle":"2025-12-15T17:32:59.328523Z","shell.execute_reply.started":"2025-12-15T17:32:54.966917Z","shell.execute_reply":"2025-12-15T17:32:59.327934Z"}},"outputs":[{"name":"stdout","text":"Python version is above 3.10, patching the collections module.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model_id = \"deepseek-ai/deepseek-vl2-tiny\"\n\nprocessor = DeepseekVLV2Processor.from_pretrained(model_id)\n\nmodel = DeepseekVLV2ForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:41:41.840846Z","iopub.execute_input":"2025-12-15T17:41:41.841205Z","iopub.status.idle":"2025-12-15T17:42:21.255562Z","shell.execute_reply.started":"2025-12-15T17:41:41.841180Z","shell.execute_reply":"2025-12-15T17:42:21.254922Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"897ecba781c84f7f8356094621091ba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d6a977f0594b1bb8045fe267cccead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/801 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51b8d8c9236e48a0991de5d44ea94b45"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"processor_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3abd69eeba14035b30c6ac7113b3320"}},"metadata":{}},{"name":"stdout","text":"Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n<｜▁pad▁｜>:2\nAdd image token = ['<image>'] to the tokenizer\n<image>:128815\nAdd grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n<|ref|>:128816\n<|/ref|>:128817\n<|det|>:128818\n<|/det|>:128819\n<|grounding|>:128820\nAdd chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n<|User|>:128821\n<|Assistant|>:128822\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62439875ee5245d3b8b0c4f1eb8a32ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12fd15707f44439cb4aeaeb0ed332679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b37ab8943f2945f3b71e7d0da64653c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-000001.safetensors:   0%|          | 0.00/6.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c721d6c71cb64c3dbfd0bfd0965724b7"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DeepseekVLV2ForCausalLM(\n  (vision): VisionTransformer(\n    (patch_embed): PatchEmbed(\n      (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n      (norm): Identity()\n    )\n    (pos_drop): Dropout(p=0.0, inplace=False)\n    (patch_drop): Identity()\n    (norm_pre): Identity()\n    (blocks): Sequential(\n      (0): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (1): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (2): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (3): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (4): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (5): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (6): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (7): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (8): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (9): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (10): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (11): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (12): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (13): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (14): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (15): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (16): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (17): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (18): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (19): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (20): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (21): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (22): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (23): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (24): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (25): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n      (26): Block(\n        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n          (q_norm): Identity()\n          (k_norm): Identity()\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n          (proj_drop): Identity()\n        )\n        (ls1): Identity()\n        (drop_path1): Identity()\n        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n          (act): GELU(approximate='tanh')\n          (drop1): Dropout(p=0.0, inplace=False)\n          (norm): Identity()\n          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n          (drop2): Dropout(p=0.0, inplace=False)\n        )\n        (ls2): Identity()\n        (drop_path2): Identity()\n      )\n    )\n    (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n    (attn_pool): AttentionPoolLatent(\n      (q): Linear(in_features=1152, out_features=1152, bias=True)\n      (kv): Linear(in_features=1152, out_features=2304, bias=True)\n      (q_norm): Identity()\n      (k_norm): Identity()\n      (proj): Linear(in_features=1152, out_features=1152, bias=True)\n      (proj_drop): Dropout(p=0.0, inplace=False)\n      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (fc_norm): Identity()\n    (head_drop): Dropout(p=0.0, inplace=False)\n    (head): Identity()\n  )\n  (projector): MlpProjector(\n    (layers): Sequential(\n      (0): Linear(in_features=4608, out_features=1280, bias=True)\n      (1): GELU(approximate='none')\n      (2): Linear(in_features=1280, out_features=1280, bias=True)\n    )\n  )\n  (language): DeepseekV2ForCausalLM(\n    (model): DeepseekV2Model(\n      (embed_tokens): Embedding(129280, 1280)\n      (layers): ModuleList(\n        (0): DeepseekV2DecoderLayer(\n          (self_attn): LlamaAttention(\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (o_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (mlp): DeepseekV2MLP(\n            (gate_proj): Linear(in_features=1280, out_features=6848, bias=False)\n            (up_proj): Linear(in_features=1280, out_features=6848, bias=False)\n            (down_proj): Linear(in_features=6848, out_features=1280, bias=False)\n            (act_fn): SiLU()\n          )\n          (input_layernorm): DeepseekV2RMSNorm()\n          (post_attention_layernorm): DeepseekV2RMSNorm()\n        )\n        (1-11): 11 x DeepseekV2DecoderLayer(\n          (self_attn): LlamaAttention(\n            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (v_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (o_proj): Linear(in_features=1280, out_features=1280, bias=False)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (mlp): DeepseekV2MoE(\n            (experts): ModuleList(\n              (0-63): 64 x DeepseekV2MLP(\n                (gate_proj): Linear(in_features=1280, out_features=896, bias=False)\n                (up_proj): Linear(in_features=1280, out_features=896, bias=False)\n                (down_proj): Linear(in_features=896, out_features=1280, bias=False)\n                (act_fn): SiLU()\n              )\n            )\n            (gate): MoEGate()\n            (shared_experts): DeepseekV2MLP(\n              (gate_proj): Linear(in_features=1280, out_features=1792, bias=False)\n              (up_proj): Linear(in_features=1280, out_features=1792, bias=False)\n              (down_proj): Linear(in_features=1792, out_features=1280, bias=False)\n              (act_fn): SiLU()\n            )\n          )\n          (input_layernorm): DeepseekV2RMSNorm()\n          (post_attention_layernorm): DeepseekV2RMSNorm()\n        )\n      )\n      (norm): DeepseekV2RMSNorm()\n    )\n    (lm_head): Linear(in_features=1280, out_features=129280, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# ==============================\n# DeepSeek-VL2 OCR (Kaggle FIXED)\n# ==============================\n\nimport time\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModelForCausalLM\nfrom deepseek_vl2.models import DeepseekVLV2Processor\n\n\n# ------------------------------\n# Timer\n# ------------------------------\ndef my_timer(func):\n    def wrapper(*args, **kwargs):\n        start = time.perf_counter()\n        result = func(*args, **kwargs)\n        end = time.perf_counter()\n        print(f\"[TIMER] {func.__name__} took {end - start:.3f} seconds\")\n        return result\n    return wrapper\n\n\n# ------------------------------\n# Device\n# ------------------------------\nassert torch.cuda.is_available(), \"❌ CUDA required on Kaggle\"\ndevice = torch.device(\"cuda\")\ntorch.backends.cuda.matmul.allow_tf32 = True\n\n\n# ------------------------------\n# OCR Runner\n# ------------------------------\n@my_timer\ndef run_deepseek_vl2(\n    image_path: str,\n    prompt_text: str,\n    model_path: str = \"deepseek-ai/deepseek-vl2-tiny\",\n    max_new_tokens: int = 512,\n):\n    # Processor\n    processor = DeepseekVLV2Processor.from_pretrained(model_path)\n    tokenizer = processor.tokenizer\n\n    # 🔥 LOAD MODEL — FP16 ONLY\n    model = AutoModelForCausalLM.from_pretrained(\n        model_path,\n        trust_remote_code=True,\n        torch_dtype=torch.float16,\n    ).to(device).eval()\n\n    # Load image\n    image = Image.open(image_path).convert(\"RGB\")\n\n    # Conversation\n    conversation = [\n        {\n            \"role\": \"<|User|>\",\n            \"content\": f\"<image>\\n{prompt_text}\",\n            \"images\": [image],\n        },\n        {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n    ]\n\n    # Processor\n    model_inputs = processor(\n        conversations=conversation,\n        images=[image],\n        force_batchify=True,\n        system_prompt=\"You are an OCR text extraction expert.\"\n    )\n\n    # 🔥🔥🔥 ABSOLUTE FIX: CAST IMAGE TENSORS TO FP16 🔥🔥🔥\n    model_inputs[\"images\"] = model_inputs[\"images\"].to(device, dtype=torch.float16)\n    model_inputs[\"images_spatial_crop\"] = model_inputs[\"images_spatial_crop\"].to(device)\n    model_inputs[\"images_seq_mask\"] = model_inputs[\"images_seq_mask\"].to(device)\n    model_inputs[\"input_ids\"] = model_inputs[\"input_ids\"].to(device)\n    model_inputs[\"attention_mask\"] = model_inputs[\"attention_mask\"].to(device)\n\n    # Vision → text embeddings\n    with torch.no_grad():\n        inputs_embeds = model.prepare_inputs_embeds(**model_inputs)\n\n        outputs = model.language.generate(\n            inputs_embeds=inputs_embeds,\n            attention_mask=model_inputs[\"attention_mask\"],\n            max_new_tokens=max_new_tokens,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n            do_sample=False,\n            use_cache=True,\n        )\n\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    print(\"\\n========== OCR RESULT ==========\\n\")\n    print(response)\n    print(\"\\n================================\\n\")\n\n    return response\n\n\n# ------------------------------\n# MAIN\n# ------------------------------\nif __name__ == \"__main__\":\n\n    model_name = \"deepseek-ai/deepseek-vl2-tiny\"\n\n    image_path = \"/kaggle/input/data-tests/data-test/4_1.jpg\"\n    prompt = \"Extract all visible text exactly as written. Include numbers and punctuation.\"\n\n    run_deepseek_vl2(\n        image_path=image_path,\n        prompt_text=prompt,\n        model_path=model_name,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T17:54:30.427233Z","iopub.execute_input":"2025-12-15T17:54:30.427568Z","iopub.status.idle":"2025-12-15T17:54:59.814327Z","shell.execute_reply.started":"2025-12-15T17:54:30.427545Z","shell.execute_reply":"2025-12-15T17:54:59.813648Z"}},"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n<｜▁pad▁｜>:2\nAdd image token = ['<image>'] to the tokenizer\n<image>:128815\nAdd grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n<|ref|>:128816\n<|/ref|>:128817\n<|det|>:128818\n<|/det|>:128819\n<|grounding|>:128820\nAdd chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n<|User|>:128821\n<|Assistant|>:128822\n\n","output_type":"stream"},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"name":"stdout","text":"\n========== OCR RESULT ==========\n\nUBND THANH PHO DA NANG  \nSO GIÁO DỤC VÀ ĐẠO TAO  \nSố: 1906 /SGDDT-CTrTT  \nV/v khán trường thứ hạng hiện cấp biện pháp phòng, chống dịch COVID-19  \n\nKinh gửi:  \n- Phòng giáo dục và đào tạo các quân, huyện;  \n- Các trường, trường tây trục thuộc Số;  \n- Các trường đại học người cống lập.  \n\nThực hiện chiêu thức dựa cũa UBND thanh phố tại Công vận sở 4869/UBND-SYT ngày 26/7/2020 về việc khán trường triển khai các biện pháp phòng, chống dịch COVID-19, Số Giáo dục và Đào tạo yêu cầu các thủ trưởng các đơn vị, trường khán trường thực hiện những mục tiêu sau:  \n\n1. Thời gian hộc sinh, hộc viên, sinh viên ngày 26/7/2020 cho đơn khách cơ quan, tín dụng tài các hoạt động tấp trung hộc sinh, hộc viên trực tiếp thực hiện theo.  \na) Học sinh, học viên cơ quan hoặc tín dụng tài các hoạt động tấp trung hộc sinh, hộc viên trực tiếp thực hiện theo.  \nb) Nhân giáo dục và đào tạo các trường đại học người cống lập cần cốt tình hinh thực hiện theo.  \nc) Các trường đại học người cống lập cần cốt tình hinh thực hiện theo.  \n\n2. Về thực hiện các biện pháp phòng, chống dịch COVID-19  \nThực hiện các đơn vị, trường khán trường thực hiện những mục tiêu sau:  \na) Trường đại học người cống lập cần\n\n================================\n\n[TIMER] run_deepseek_vl2 took 29.377 seconds\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}